{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30579c96-f32d-4485-91ea-429c234a75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18eb2be6-7dfe-4376-8e24-d8fd6b5f2e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "                                category                       sub_category  \\\n",
      "0  Online and Social Media Related Crime  Cyber Bullying  Stalking  Sexting   \n",
      "1                 Online Financial Fraud                  Fraud CallVishing   \n",
      "2               Online Gambling  Betting           Online Gambling  Betting   \n",
      "3  Online and Social Media Related Crime                   Online Job Fraud   \n",
      "4                 Online Financial Fraud                  Fraud CallVishing   \n",
      "\n",
      "                                  crimeaditionalinfo  \n",
      "0  I had continue received random calls and abusi...  \n",
      "1  The above fraudster is continuously messaging ...  \n",
      "2  He is acting like a police and demanding for m...  \n",
      "3  In apna Job I have applied for job interview f...  \n",
      "4  I received a call from lady stating that she w...  \n",
      "\n",
      "Test Dataset:\n",
      "                                    category  \\\n",
      "0  RapeGang Rape RGRSexually Abusive Content   \n",
      "1                     Online Financial Fraud   \n",
      "2             Cyber Attack/ Dependent Crimes   \n",
      "3                     Online Financial Fraud   \n",
      "4                      Any Other Cyber Crime   \n",
      "\n",
      "                           sub_category  \\\n",
      "0                                   NaN   \n",
      "1  DebitCredit Card FraudSim Swap Fraud   \n",
      "2                         SQL Injection   \n",
      "3                     Fraud CallVishing   \n",
      "4                                 Other   \n",
      "\n",
      "                                  crimeaditionalinfo  \n",
      "0  Sir namaskar  mein Ranjit Kumar PatraPaise neh...  \n",
      "1          KOTAK MAHINDRA BANK FRAUD\\r\\nFRAUD AMOUNT  \n",
      "2  The issue actually started when I got this ema...  \n",
      "3  I am amit kumar from karwi chitrakoot I am tot...  \n",
      "4  I have ordered  saree and  blouse from rinki s...  \n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee41a5b7-a0d5-4936-af24-860b76ecce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Train Dataset:\n",
      "category                 0\n",
      "sub_category          6591\n",
      "crimeaditionalinfo      21\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Test Dataset:\n",
      "category                 0\n",
      "sub_category          2236\n",
      "crimeaditionalinfo       7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in Train Dataset:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing values in Test Dataset:\")\n",
    "print(test_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23726854-9c9b-4cf3-955e-ea6e5cc7260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with empty strings (if the column is text-based)\n",
    "train_df = train_df.fillna(\"\")\n",
    "test_df = test_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5922c92c-f166-4d72-a98c-8703917a8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akbas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akbas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  crimeaditionalinfo  \\\n",
      "0  I had continue received random calls and abusi...   \n",
      "1  The above fraudster is continuously messaging ...   \n",
      "2  He is acting like a police and demanding for m...   \n",
      "3  In apna Job I have applied for job interview f...   \n",
      "4  I received a call from lady stating that she w...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  continu receiv random call abus messag whatsap...  \n",
      "1  fraudster continu messag ask pay money send fa...  \n",
      "2  act like polic demand money ad section text me...  \n",
      "3  apna job appli job interview telecal resourc m...  \n",
      "4  receiv call ladi state send new phone vivo rec...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Define a text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into a string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to the `crimeaditionalinfo` column\n",
    "train_df[\"cleaned_text\"] = train_df[\"crimeaditionalinfo\"].apply(preprocess_text)\n",
    "test_df[\"cleaned_text\"] = test_df[\"crimeaditionalinfo\"].apply(preprocess_text)\n",
    "\n",
    "# Check the processed text\n",
    "print(train_df[[\"crimeaditionalinfo\", \"cleaned_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0c3b98-08ed-472d-8ed0-3b9024ea8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen labels found: ['Crime Against Women & Children', 'Crime Against Women & Children', 'Crime Against Women & Children', 'Crime Against Women & Children']\n",
      "Unseen labels found: ['Computer Generated CSAM/CSEM', 'Computer Generated CSAM/CSEM', 'Cyber Blackmailing & Threatening', 'Sexual Harassment']\n",
      "                                                category  category_encoded\n",
      "0                  Online and Social Media Related Crime                 9\n",
      "1                                 Online Financial Fraud                 7\n",
      "2                               Online Gambling  Betting                 8\n",
      "8              RapeGang Rape RGRSexually Abusive Content                11\n",
      "9                                  Any Other Cyber Crime                 0\n",
      "20                        Cyber Attack/ Dependent Crimes                 3\n",
      "30                                  Cryptocurrency Crime                 2\n",
      "39                                 Sexually Explicit Act                13\n",
      "45                             Sexually Obscene material                14\n",
      "81        Hacking  Damage to computercomputer system etc                 5\n",
      "197                                      Cyber Terrorism                 4\n",
      "276    Child Pornography CPChild Sexual Abuse Materia...                 1\n",
      "371                             Online Cyber Trafficking                 6\n",
      "2420                                          Ransomware                10\n",
      "84508                            Report Unlawful Content                12\n",
      "                                            sub_category  sub_category_encoded\n",
      "0                      Cyber Bullying  Stalking  Sexting                     5\n",
      "1                                      Fraud CallVishing                    16\n",
      "2                               Online Gambling  Betting                    22\n",
      "3                                       Online Job Fraud                    23\n",
      "5                                     UPI Related Frauds                    33\n",
      "7                         Internet Banking Related Fraud                    19\n",
      "8                                                                            0\n",
      "9                                                  Other                    26\n",
      "12                        Profile Hacking Identity Theft                    27\n",
      "13                  DebitCredit Card FraudSim Swap Fraud                     9\n",
      "18                                 EWallet Related Fraud                    13\n",
      "20                                     Data Breach/Theft                     8\n",
      "23                             Cheating by Impersonation                     3\n",
      "24     Denial of Service (DoS)/Distributed Denial of ...                    11\n",
      "27                             FakeImpersonating Profile                    15\n",
      "30                                  Cryptocurrency Fraud                     4\n",
      "60                                        Malware Attack                    21\n",
      "63               Business Email CompromiseEmail Takeover                     2\n",
      "81                                         Email Hacking                    14\n",
      "106                                   Hacking/Defacement                    17\n",
      "119                       Unauthorised AccessData Breach                    34\n",
      "167                                        SQL Injection                    31\n",
      "177                 Provocative Speech for unlawful acts                    28\n",
      "193                                    Ransomware Attack                    30\n",
      "197                                      Cyber Terrorism                     6\n",
      "300             Tampering with computer source documents                    32\n",
      "331                                DematDepository Fraud                    10\n",
      "371                                   Online Trafficking                    25\n",
      "419                             Online Matrimonial Fraud                    24\n",
      "539                            Website DefacementHacking                    35\n",
      "920              Damage to computer computer systems etc                     7\n",
      "1058                                 Impersonating Email                    18\n",
      "1399                                      EMail Phishing                    12\n",
      "2420                                          Ransomware                    29\n",
      "3141                                  Intimidating Email                    20\n",
      "84508  Against Interest of sovereignty or integrity o...                     1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categories with error handling for unseen labels\n",
    "def transform_with_unseen_labels(encoder, values):\n",
    "    try:\n",
    "        return encoder.transform(values)\n",
    "    except ValueError as e:\n",
    "        # Handle unseen labels\n",
    "        unseen_labels = [v for v in values if v not in encoder.classes_]\n",
    "        if unseen_labels:\n",
    "            print(f\"Unseen labels found: {unseen_labels}\")\n",
    "        return np.array([encoder.transform([v])[0] if v in encoder.classes_ else -1 for v in values])\n",
    "\n",
    "# Initialize the encoders\n",
    "category_encoder = LabelEncoder()\n",
    "sub_category_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels for training data\n",
    "train_df[\"category_encoded\"] = category_encoder.fit_transform(train_df[\"category\"])\n",
    "train_df[\"sub_category_encoded\"] = sub_category_encoder.fit_transform(train_df[\"sub_category\"])\n",
    "\n",
    "# Handle unseen labels in test set\n",
    "test_df[\"category_encoded\"] = transform_with_unseen_labels(category_encoder, test_df[\"category\"])\n",
    "test_df[\"sub_category_encoded\"] = transform_with_unseen_labels(sub_category_encoder, test_df[\"sub_category\"])\n",
    "\n",
    "# Check the encoded columns\n",
    "print(train_df[[\"category\", \"category_encoded\"]].drop_duplicates())\n",
    "print(train_df[[\"sub_category\", \"sub_category_encoded\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d3999f-8bad-451a-a4c3-cab61bec7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                category  category_encoded\n",
      "0                  Online and Social Media Related Crime                10\n",
      "1                                 Online Financial Fraud                 8\n",
      "2                               Online Gambling  Betting                 9\n",
      "8              RapeGang Rape RGRSexually Abusive Content                12\n",
      "9                                  Any Other Cyber Crime                 0\n",
      "20                        Cyber Attack/ Dependent Crimes                 4\n",
      "30                                  Cryptocurrency Crime                 3\n",
      "39                                 Sexually Explicit Act                14\n",
      "45                             Sexually Obscene material                15\n",
      "81        Hacking  Damage to computercomputer system etc                 6\n",
      "197                                      Cyber Terrorism                 5\n",
      "276    Child Pornography CPChild Sexual Abuse Materia...                 1\n",
      "371                             Online Cyber Trafficking                 7\n",
      "2420                                          Ransomware                11\n",
      "84508                            Report Unlawful Content                13\n",
      "                                            sub_category  sub_category_encoded\n",
      "0                      Cyber Bullying  Stalking  Sexting                     7\n",
      "1                                      Fraud CallVishing                    18\n",
      "2                               Online Gambling  Betting                    24\n",
      "3                                       Online Job Fraud                    25\n",
      "5                                     UPI Related Frauds                    36\n",
      "7                         Internet Banking Related Fraud                    21\n",
      "8                                                                            0\n",
      "9                                                  Other                    28\n",
      "12                        Profile Hacking Identity Theft                    29\n",
      "13                  DebitCredit Card FraudSim Swap Fraud                    11\n",
      "18                                 EWallet Related Fraud                    15\n",
      "20                                     Data Breach/Theft                    10\n",
      "23                             Cheating by Impersonation                     3\n",
      "24     Denial of Service (DoS)/Distributed Denial of ...                    13\n",
      "27                             FakeImpersonating Profile                    17\n",
      "30                                  Cryptocurrency Fraud                     5\n",
      "60                                        Malware Attack                    23\n",
      "63               Business Email CompromiseEmail Takeover                     2\n",
      "81                                         Email Hacking                    16\n",
      "106                                   Hacking/Defacement                    19\n",
      "119                       Unauthorised AccessData Breach                    37\n",
      "167                                        SQL Injection                    33\n",
      "177                 Provocative Speech for unlawful acts                    30\n",
      "193                                    Ransomware Attack                    32\n",
      "197                                      Cyber Terrorism                     8\n",
      "300             Tampering with computer source documents                    35\n",
      "331                                DematDepository Fraud                    12\n",
      "371                                   Online Trafficking                    27\n",
      "419                             Online Matrimonial Fraud                    26\n",
      "539                            Website DefacementHacking                    38\n",
      "920              Damage to computer computer systems etc                     9\n",
      "1058                                 Impersonating Email                    20\n",
      "1399                                      EMail Phishing                    14\n",
      "2420                                          Ransomware                    31\n",
      "3141                                  Intimidating Email                    22\n",
      "84508  Against Interest of sovereignty or integrity o...                     1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categories with error handling for unseen labels\n",
    "def transform_with_unseen_labels(encoder, values):\n",
    "    try:\n",
    "        return encoder.transform(values)\n",
    "    except ValueError as e:\n",
    "        # Handle unseen labels\n",
    "        unseen_labels = [v for v in values if v not in encoder.classes_]\n",
    "        if unseen_labels:\n",
    "            print(f\"Unseen labels found: {unseen_labels}\")\n",
    "        return np.array([encoder.transform([v])[0] if v in encoder.classes_ else -1 for v in values])\n",
    "\n",
    "# Initialize the encoders\n",
    "category_encoder = LabelEncoder()\n",
    "sub_category_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels for training data\n",
    "train_df[\"category_encoded\"] = category_encoder.fit_transform(train_df[\"category\"])\n",
    "train_df[\"sub_category_encoded\"] = sub_category_encoder.fit_transform(train_df[\"sub_category\"])\n",
    "\n",
    "# Handle unseen labels in test set\n",
    "test_df[\"category_encoded\"] = transform_with_unseen_labels(category_encoder, test_df[\"category\"])\n",
    "test_df[\"sub_category_encoded\"] = transform_with_unseen_labels(sub_category_encoder, test_df[\"sub_category\"])\n",
    "\n",
    "# Check the encoded columns\n",
    "print(train_df[[\"category\", \"category_encoded\"]].drop_duplicates())\n",
    "print(train_df[[\"sub_category\", \"sub_category_encoded\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e40f0c-3599-46e7-b2a1-c3ea78f34a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category                0\n",
      "sub_category            0\n",
      "crimeaditionalinfo      0\n",
      "cleaned_text            0\n",
      "category_encoded        0\n",
      "sub_category_encoded    0\n",
      "dtype: int64\n",
      "category                0\n",
      "sub_category            0\n",
      "crimeaditionalinfo      0\n",
      "cleaned_text            0\n",
      "category_encoded        0\n",
      "sub_category_encoded    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akbas\\AppData\\Local\\Temp\\ipykernel_3964\\1447969593.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['crimeaditionalinfo'].fillna('', inplace=True)\n",
      "C:\\Users\\akbas\\AppData\\Local\\Temp\\ipykernel_3964\\1447969593.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['crimeaditionalinfo'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Example: Fill missing values in the 'crimeaditionalinfo' column\n",
    "train_df['crimeaditionalinfo'].fillna('', inplace=True)\n",
    "test_df['crimeaditionalinfo'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e578a7af-779d-48f1-b881-72df7a3718cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit the number of features\n",
    "train_text_features = vectorizer.fit_transform(train_df['crimeaditionalinfo'])\n",
    "test_text_features = vectorizer.transform(test_df['crimeaditionalinfo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2a0ef5c-5960-4aa8-8ae2-ef408759c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features\n",
    "train_features = sp.hstack([\n",
    "    train_text_features, \n",
    "    train_df[['category_encoded', 'sub_category_encoded']]\n",
    "])\n",
    "\n",
    "test_features = sp.hstack([\n",
    "    test_text_features, \n",
    "    test_df[['category_encoded', 'sub_category_encoded']]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c5d1f9-532a-46a3-b5b1-09698f42d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'sub_category', 'crimeaditionalinfo', 'cleaned_text',\n",
      "       'category_encoded', 'sub_category_encoded'],\n",
      "      dtype='object')\n",
      "Index(['category', 'sub_category', 'crimeaditionalinfo', 'cleaned_text',\n",
      "       'category_encoded', 'sub_category_encoded'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82923f60-b520-49d0-8d61-e029d4b43d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635bce80-7f9d-4294-8222-d07ed2ab300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'sub_category', 'crimeaditionalinfo'], dtype='object')\n",
      "Index(['category', 'sub_category', 'crimeaditionalinfo'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "print(test_df.columns)\n",
    "# Now you can safely assign y_train\n",
    "y_train = train_df['sub_category']\n",
    "# Load your dataset\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a48656a-cdcf-4d4b-8507-574f90ea3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target (labels)\n",
    "X = train_df.drop('sub_category', axis=1)  # Assuming 'sub_category' is the target\n",
    "y = train_df['sub_category']\n",
    "x = test_df.drop('sub_category', axis=1)\n",
    "y = test_df['sub_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b5720c1-abf2-4760-8b86-bafb3e5de483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category              object\n",
      "sub_category          object\n",
      "crimeaditionalinfo    object\n",
      "dtype: object\n",
      "category              object\n",
      "sub_category          object\n",
      "crimeaditionalinfo    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.dtypes)\n",
    "print(test_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a4b935-d2c6-4173-a99c-12de1959630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example: Convert 'sub_category' (the target) to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(train_df['sub_category'])\n",
    "\n",
    "# Now proceed with splitting the data as before\n",
    "X = train_df.drop('sub_category', axis=1)  # features\n",
    "# Example: Convert 'sub_category' (the target) to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(test_df['sub_category'])\n",
    "\n",
    "# Now proceed with splitting the data as before\n",
    "X = test_df.drop('sub_category', axis=1)  # features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e381fa-30e1-4db4-ad26-8f017d2f3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns in X\n",
    "X = pd.get_dummies(train_df.drop('sub_category', axis=1))\n",
    "\n",
    "# Now `X` contains numerical data, you can use it with RandomForestClassifier\n",
    "y = train_df['sub_category']\n",
    "# One-hot encode categorical columns in X\n",
    "X = pd.get_dummies(test_df.drop('sub_category', axis=1))\n",
    "\n",
    "# Now `X` contains numerical data, you can use it with RandomForestClassifier\n",
    "y = test_df['sub_category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54fcec2c-2d11-43bc-97ab-e0a323b100e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading data from a CSV file into X\n",
    "X = pd.read_csv('train.csv')\n",
    "\n",
    "# Fill missing values with the most frequent category in each column\n",
    "X = X.apply(lambda col: col.fillna(col.mode()[0]), axis=0)\n",
    "# Example: Loading data from a CSV file into X\n",
    "X = pd.read_csv('test.csv')\n",
    "\n",
    "# Fill missing values with the most frequent category in each column\n",
    "X = X.apply(lambda col: col.fillna(col.mode()[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bb3b905-c63e-4bc3-8ced-b131ac28c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10000  # Adjust based on your memory capacity\n",
    "for start in range(0, len(X), chunk_size):\n",
    "    end = start + chunk_size\n",
    "    chunk = X.iloc[start:end]\n",
    "    chunk = chunk.apply(lambda col: col.fillna(col.mode()[0]), axis=0)\n",
    "    # Append the modified chunk back to the original dataset\n",
    "    X.iloc[start:end] = chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7acfb31-4f5b-407c-8b78-a1447c2339bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akbas\\AppData\\Local\\Temp\\ipykernel_3964\\2802297527.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  X = X.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Forward fill the missing values\n",
    "X = X.fillna(method='ffill')\n",
    "\n",
    "# Backward fill the missing values\n",
    "# X = X.fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "189afab8-859a-4082-a17d-d3e3446b323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a memory-mapped array if needed for large datasets\n",
    "X = np.memmap('my_data.dat', dtype='bool', mode='w+', shape=(85028, 93686))\n",
    "\n",
    "# After that, apply the operation\n",
    "X = pd.DataFrame(X)\n",
    "X = X.apply(lambda col: col.fillna(col.mode()[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b3e54d9-2983-4c1b-afa8-b679d5c1d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 0\n",
      "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
      "0  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "1  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "2  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "3  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "4  False  False  False  False  False  False  False  False  False  False  ...   \n",
      "\n",
      "   93676  93677  93678  93679  93680  93681  93682  93683  93684  93685  \n",
      "0  False  False  False  False  False  False  False  False  False  False  \n",
      "1  False  False  False  False  False  False  False  False  False  False  \n",
      "2  False  False  False  False  False  False  False  False  False  False  \n",
      "3  False  False  False  False  False  False  False  False  False  False  \n",
      "4  False  False  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[5 rows x 93686 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any remaining missing values\n",
    "missing_values = X.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_values}\")\n",
    "\n",
    "# Verify the filled values by inspecting the first few rows\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8998db56-1d62-4360-a6fe-63bc6804a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming X is your original dataset\n",
    "X_sparse = csr_matrix(X)  # Convert to sparse format if it's sparse\n",
    "scaler = StandardScaler(with_mean=False)  # Don't center sparse matrices\n",
    "X_scaled = scaler.fit_transform(X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f355b6-ddd1-4844-9c64-3ff5fe76f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop('sub_category', axis=1)  # Features\n",
    "y = df['sub_category']  # Target variable\n",
    "df = pd.read_csv('test.csv')\n",
    "X = df.drop('sub_category', axis=1)  # Features\n",
    "y = df['sub_category']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69bdbae2-88f7-412e-b692-be7a8322b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data  # Feature set\n",
    "y = iris.target  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821e7322-79b8-40ec-8839-ca3ee226b682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Example: Assume you have already loaded or prepared your data\n",
    "# Example feature set (X) and target variable (y)\n",
    "# train_features = some_dataframe_or_numpy_array_of_features\n",
    "# y_train = some_array_or_series_of_labels\n",
    "\n",
    "# You need to load or create your features and target variables before proceeding\n",
    "# Example:\n",
    "# X = df.drop('target_column', axis=1)  # Features\n",
    "# y = df['target_column']  # Target variable\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split( iris.data , iris.target, test_size=0.2, random_state=500000)\n",
    "# Split data into training and validation sets\n",
    "X_test, X_val, y_test, y_val = train_test_split( iris.data , iris.target, test_size=0.2, random_state=50000)\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# Train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_test, y_test)\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "987b49c6-87c9-44a9-8a7b-1ef98ebc6991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "accuracy_percentage = accuracy_score(y_val, y_pred) * 100\n",
    "print(f\"Accuracy: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72745128-0bd4-4957-aed7-7c3c25be6377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
